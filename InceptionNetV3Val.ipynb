{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6695bb98-f736-4a86-a8e1-6e522e7c0c5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T10:17:21.967458Z",
     "start_time": "2023-03-28T10:17:19.324204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4864 images belonging to 4 classes.\n",
      "Found 1216 images belonging to 4 classes.\n",
      "Found 1520 images belonging to 4 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions, InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import tensorflow as tf\n",
    "\n",
    "img_height, img_width = (224, 224)\n",
    "batch_size = 16\n",
    "\n",
    "trainvalid_data_dir = '/mnt/Project-2/Leather image datasets/V2/trainvalidation'\n",
    "test_data_dir  = '/mnt/Project-2/Leather image datasets/V2/test'\n",
    "datagen = ImageDataGenerator(preprocessing_function = preprocess_input,\n",
    "                                  shear_range = 0,\n",
    "                                  zoom_range = 0,\n",
    "                                  horizontal_flip = False,\n",
    "                                  validation_split = 0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    trainvalid_data_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    subset = 'training')\n",
    "\n",
    "valid_generator = datagen.flow_from_directory(\n",
    "    trainvalid_data_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    subset = 'validation')\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = 1,\n",
    "    class_mode = 'categorical')\n",
    "\n",
    "x, y = test_generator.next()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52eea02f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T11:09:49.481352Z",
     "start_time": "2023-03-28T10:17:33.641016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "304/304 [==============================] - 56s 164ms/step - loss: 1.4774 - accuracy: 0.3803 - val_loss: 1.5011 - val_accuracy: 0.2311\n",
      "Epoch 2/100\n",
      "304/304 [==============================] - 49s 162ms/step - loss: 1.1190 - accuracy: 0.4890 - val_loss: 1.3267 - val_accuracy: 0.4498\n",
      "Epoch 3/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.9519 - accuracy: 0.5700 - val_loss: 2.6337 - val_accuracy: 0.5115\n",
      "Epoch 4/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.7254 - accuracy: 0.6642 - val_loss: 0.7144 - val_accuracy: 0.7319\n",
      "Epoch 5/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.6567 - accuracy: 0.7108 - val_loss: 0.7132 - val_accuracy: 0.6990\n",
      "Epoch 6/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.5668 - accuracy: 0.7769 - val_loss: 0.9286 - val_accuracy: 0.6941\n",
      "Epoch 7/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.4713 - accuracy: 0.8216 - val_loss: 0.4810 - val_accuracy: 0.8372\n",
      "Epoch 8/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.4640 - accuracy: 0.8209 - val_loss: 0.4425 - val_accuracy: 0.8561\n",
      "Epoch 9/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.3478 - accuracy: 0.8758 - val_loss: 0.2936 - val_accuracy: 0.9054\n",
      "Epoch 10/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.2927 - accuracy: 0.8899 - val_loss: 0.5335 - val_accuracy: 0.8322\n",
      "Epoch 11/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.2150 - accuracy: 0.9271 - val_loss: 0.2760 - val_accuracy: 0.9112\n",
      "Epoch 12/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.2165 - accuracy: 0.9319 - val_loss: 0.4254 - val_accuracy: 0.8544\n",
      "Epoch 13/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.1625 - accuracy: 0.9412 - val_loss: 0.2346 - val_accuracy: 0.9169\n",
      "Epoch 14/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.1735 - accuracy: 0.9413 - val_loss: 0.7624 - val_accuracy: 0.7788\n",
      "Epoch 15/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.2030 - accuracy: 0.9320 - val_loss: 0.3901 - val_accuracy: 0.9260\n",
      "Epoch 16/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.1416 - accuracy: 0.9506 - val_loss: 0.4876 - val_accuracy: 0.8676\n",
      "Epoch 17/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.1278 - accuracy: 0.9592 - val_loss: 0.2509 - val_accuracy: 0.9408\n",
      "Epoch 18/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.1088 - accuracy: 0.9621 - val_loss: 0.2619 - val_accuracy: 0.9161\n",
      "Epoch 19/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.1002 - accuracy: 0.9683 - val_loss: 146.7154 - val_accuracy: 0.5222\n",
      "Epoch 20/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.1268 - accuracy: 0.9589 - val_loss: 2.8293 - val_accuracy: 0.8512\n",
      "Epoch 21/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.1551 - accuracy: 0.9518 - val_loss: 0.2595 - val_accuracy: 0.9145\n",
      "Epoch 22/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0999 - accuracy: 0.9708 - val_loss: 0.4459 - val_accuracy: 0.8536\n",
      "Epoch 23/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.1047 - accuracy: 0.9700 - val_loss: 0.3035 - val_accuracy: 0.9202\n",
      "Epoch 24/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.1163 - accuracy: 0.9671 - val_loss: 0.1617 - val_accuracy: 0.9424\n",
      "Epoch 25/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0694 - accuracy: 0.9789 - val_loss: 0.1845 - val_accuracy: 0.9507\n",
      "Epoch 26/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0421 - accuracy: 0.9871 - val_loss: 0.3965 - val_accuracy: 0.8914\n",
      "Epoch 27/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0679 - accuracy: 0.9813 - val_loss: 0.0859 - val_accuracy: 0.9737\n",
      "Epoch 28/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0537 - accuracy: 0.9828 - val_loss: 0.1916 - val_accuracy: 0.9383\n",
      "Epoch 29/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0385 - accuracy: 0.9873 - val_loss: 0.5902 - val_accuracy: 0.8816\n",
      "Epoch 30/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0444 - accuracy: 0.9877 - val_loss: 0.1565 - val_accuracy: 0.9613\n",
      "Epoch 31/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0574 - accuracy: 0.9827 - val_loss: 0.1396 - val_accuracy: 0.9671\n",
      "Epoch 32/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0479 - accuracy: 0.9827 - val_loss: 0.0758 - val_accuracy: 0.9737\n",
      "Epoch 33/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0342 - accuracy: 0.9906 - val_loss: 0.2940 - val_accuracy: 0.8980\n",
      "Epoch 34/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0394 - accuracy: 0.9879 - val_loss: 0.2321 - val_accuracy: 0.9441\n",
      "Epoch 35/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0504 - accuracy: 0.9856 - val_loss: 0.3448 - val_accuracy: 0.9268\n",
      "Epoch 36/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0353 - accuracy: 0.9878 - val_loss: 0.3935 - val_accuracy: 0.8832\n",
      "Epoch 37/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0454 - accuracy: 0.9873 - val_loss: 0.3659 - val_accuracy: 0.9457\n",
      "Epoch 38/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0342 - accuracy: 0.9901 - val_loss: 0.4395 - val_accuracy: 0.8898\n",
      "Epoch 39/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0305 - accuracy: 0.9892 - val_loss: 0.1026 - val_accuracy: 0.9663\n",
      "Epoch 40/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0530 - accuracy: 0.9832 - val_loss: 0.2244 - val_accuracy: 0.9474\n",
      "Epoch 41/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0409 - accuracy: 0.9871 - val_loss: 0.2169 - val_accuracy: 0.9507\n",
      "Epoch 42/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0313 - accuracy: 0.9898 - val_loss: 0.4997 - val_accuracy: 0.8709\n",
      "Epoch 43/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0193 - accuracy: 0.9924 - val_loss: 0.1600 - val_accuracy: 0.9655\n",
      "Epoch 44/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.1259 - val_accuracy: 0.9745\n",
      "Epoch 45/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0426 - accuracy: 0.9873 - val_loss: 0.1100 - val_accuracy: 0.9663\n",
      "Epoch 46/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0359 - accuracy: 0.9904 - val_loss: 0.4829 - val_accuracy: 0.8931\n",
      "Epoch 47/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0278 - accuracy: 0.9910 - val_loss: 0.1421 - val_accuracy: 0.9556\n",
      "Epoch 48/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0320 - accuracy: 0.9915 - val_loss: 0.0870 - val_accuracy: 0.9745\n",
      "Epoch 49/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 0.2695 - val_accuracy: 0.9202\n",
      "Epoch 50/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0400 - accuracy: 0.9890 - val_loss: 0.4480 - val_accuracy: 0.9046\n",
      "Epoch 51/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0269 - accuracy: 0.9924 - val_loss: 0.1200 - val_accuracy: 0.9663\n",
      "Epoch 52/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0161 - accuracy: 0.9965 - val_loss: 0.1697 - val_accuracy: 0.9539\n",
      "Epoch 53/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0162 - accuracy: 0.9956 - val_loss: 0.2313 - val_accuracy: 0.9498\n",
      "Epoch 54/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.1680 - val_accuracy: 0.9671\n",
      "Epoch 55/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0400 - accuracy: 0.9879 - val_loss: 0.3057 - val_accuracy: 0.9268\n",
      "Epoch 56/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0481 - accuracy: 0.9862 - val_loss: 0.1365 - val_accuracy: 0.9589\n",
      "Epoch 57/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.0410 - val_accuracy: 0.9827\n",
      "Epoch 58/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.2481 - val_accuracy: 0.9490\n",
      "Epoch 59/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 0.1314 - val_accuracy: 0.9646\n",
      "Epoch 60/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0264 - accuracy: 0.9905 - val_loss: 0.5564 - val_accuracy: 0.9030\n",
      "Epoch 61/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 0.0471 - val_accuracy: 0.9868\n",
      "Epoch 62/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0278 - accuracy: 0.9928 - val_loss: 0.2039 - val_accuracy: 0.9408\n",
      "Epoch 63/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.1898 - val_accuracy: 0.9564\n",
      "Epoch 64/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.1309 - val_accuracy: 0.9720\n",
      "Epoch 65/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.1003 - val_accuracy: 0.9712\n",
      "Epoch 66/100\n",
      "304/304 [==============================] - 49s 161ms/step - loss: 0.0301 - accuracy: 0.9929 - val_loss: 0.0802 - val_accuracy: 0.9729\n",
      "Epoch 67/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.1871 - val_accuracy: 0.9465\n",
      "Epoch 68/100\n",
      "304/304 [==============================] - 49s 159ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.2828 - val_accuracy: 0.9350\n",
      "Epoch 69/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.1333 - val_accuracy: 0.9663\n",
      "Epoch 70/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0166 - accuracy: 0.9960 - val_loss: 0.4711 - val_accuracy: 0.9062\n",
      "Epoch 71/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 0.2718 - val_accuracy: 0.9293\n",
      "Epoch 72/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0248 - accuracy: 0.9943 - val_loss: 0.1817 - val_accuracy: 0.9548\n",
      "Epoch 73/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0250 - accuracy: 0.9909 - val_loss: 0.6164 - val_accuracy: 0.8627\n",
      "Epoch 74/100\n",
      "304/304 [==============================] - 49s 159ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.6410 - val_accuracy: 0.8857\n",
      "Epoch 75/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0085 - accuracy: 0.9953 - val_loss: 0.1195 - val_accuracy: 0.9712\n",
      "Epoch 76/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0363 - accuracy: 0.9902 - val_loss: 0.1643 - val_accuracy: 0.9630\n",
      "Epoch 77/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.7710 - val_accuracy: 0.8660\n",
      "Epoch 78/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0115 - accuracy: 0.9968 - val_loss: 0.0959 - val_accuracy: 0.9786\n",
      "Epoch 79/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0041 - accuracy: 0.9982 - val_loss: 0.5984 - val_accuracy: 0.8956\n",
      "Epoch 80/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 0.2527 - val_accuracy: 0.9712\n",
      "Epoch 81/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.3155 - val_accuracy: 0.9359\n",
      "Epoch 82/100\n",
      "304/304 [==============================] - 48s 159ms/step - loss: 0.0273 - accuracy: 0.9937 - val_loss: 0.2547 - val_accuracy: 0.9655\n",
      "Epoch 83/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 0.6903 - val_accuracy: 0.9433\n",
      "Epoch 84/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0426 - accuracy: 0.9918 - val_loss: 0.1654 - val_accuracy: 0.9581\n",
      "Epoch 85/100\n",
      "304/304 [==============================] - 49s 159ms/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.1576 - val_accuracy: 0.9498\n",
      "Epoch 86/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.2024 - val_accuracy: 0.9597\n",
      "Epoch 87/100\n",
      "304/304 [==============================] - 49s 159ms/step - loss: 0.0286 - accuracy: 0.9938 - val_loss: 0.5594 - val_accuracy: 0.8035\n",
      "Epoch 88/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0379 - accuracy: 0.9880 - val_loss: 0.1630 - val_accuracy: 0.9605\n",
      "Epoch 89/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.0836 - val_accuracy: 0.9737\n",
      "Epoch 90/100\n",
      "304/304 [==============================] - 49s 159ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.1659 - val_accuracy: 0.9613\n",
      "Epoch 91/100\n",
      "304/304 [==============================] - 48s 159ms/step - loss: 0.0153 - accuracy: 0.9965 - val_loss: 0.0920 - val_accuracy: 0.9663\n",
      "Epoch 92/100\n",
      "304/304 [==============================] - 49s 159ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 0.8050 - val_accuracy: 0.8520\n",
      "Epoch 93/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0104 - accuracy: 0.9977 - val_loss: 0.4562 - val_accuracy: 0.8668\n",
      "Epoch 94/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0243 - accuracy: 0.9935 - val_loss: 0.0885 - val_accuracy: 0.9679\n",
      "Epoch 95/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 9.7494e-04 - accuracy: 0.9998 - val_loss: 0.1896 - val_accuracy: 0.9482\n",
      "Epoch 96/100\n",
      "304/304 [==============================] - 48s 159ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.0568 - val_accuracy: 0.9836\n",
      "Epoch 97/100\n",
      "304/304 [==============================] - 49s 159ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0933 - val_accuracy: 0.9688\n",
      "Epoch 98/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0092 - accuracy: 0.9978 - val_loss: 0.0716 - val_accuracy: 0.9852\n",
      "Epoch 99/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0148 - accuracy: 0.9948 - val_loss: 0.1236 - val_accuracy: 0.9622\n",
      "Epoch 100/100\n",
      "304/304 [==============================] - 49s 160ms/step - loss: 0.0128 - accuracy: 0.9946 - val_loss: 0.0685 - val_accuracy: 0.9770\n"
     ]
    }
   ],
   "source": [
    "# configuring model\n",
    "base_model = InceptionV3(include_top = False, \n",
    "                      weights = None) \n",
    "\n",
    "x = base_model.output \n",
    "x = GlobalAveragePooling2D()(x) \n",
    "x = Dense(1024, activation = 'relu')(x) \n",
    "\n",
    "x = Dense(512, activation = 'relu')(x)\n",
    "predictions = Dense(train_generator.num_classes, activation = 'softmax')(x) \n",
    "\n",
    "model = Model(inputs = base_model.input, outputs = predictions) \n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# earlystopper = EarlyStopping(monitor=\"loss\", patience=10, verbose=1)\n",
    "\n",
    "# history = model.fit(train_generator, epochs = 100, validation_data=valid_generator, callbacks=[earlystopper])\n",
    "\n",
    "history = model.fit(train_generator, epochs = 100, validation_data=valid_generator)\n",
    "model.save('inceptionNetV3_100eVAL_16b_v2_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca7b2b04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T11:14:46.681242Z",
     "start_time": "2023-03-28T11:14:46.308025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, None, None, 3 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, None, 3 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, None, 3 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 3 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, None, None, 6 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 6 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 6 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, None, None, 6 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 8 5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 8 240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 8 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 1 138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 1 576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 1 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 1 0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 9 55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 4 144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 9 288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 4 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 9 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, None, None, 1 0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 6 76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 9 82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 3 6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 6 192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 6 192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 3 96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 6 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 6 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 3 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 6 192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 9 55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 4 144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 9 288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 4 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 9 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 6 76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 9 82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 6 16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 6 192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 6 192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 9 288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, None, 6 192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 6 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 6 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 9 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 6 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 6 192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 6 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 9 55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 4 144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 9 288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, None, 4 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 9 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 6 76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 9 82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 6 18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 6 192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 6 192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 9 288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, None, 6 192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, None, 6 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, None, 6 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 9 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 6 0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, None, 6 192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 6 0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 9 55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 9 288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 9 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, None, None, 9 82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, None, 3 1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 9 288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 3 0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, None, 9 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 1 384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, None, None, 1 114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 1 384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 1 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, None, None, 1 114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 1 384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 1 384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 1 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 1 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, None, None, 1 114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, None, None, 1 114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 1 384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 1 384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 1 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, None, None, 1 172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, None, None, 1 172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 1 576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 1 576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 1 576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 1 576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, None, 1 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 1 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 1 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 1 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 1 480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, None, None, 1 179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 1 480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 1 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, None, None, 1 179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 1 480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 1 480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 1 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, None, None, 1 179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, None, None, 1 179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 1 480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 1 480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 1 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 1 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, None, None, 1 215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, None, None, 1 215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 1 576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 1 576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 1 576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 1 576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 1 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 1 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, None, None, 1 480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, None, None, 1 179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, None, None, 1 480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 1 0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, None, None, 1 179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 1 480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, None, None, 1 480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 1 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, None, None, 1 179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, None, None, 1 179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 1 480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, None, None, 1 480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, None, None, 1 0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, None, None, 1 215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 1 215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 1 576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 1 576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, None, None, 1 576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, None, None, 1 576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 1 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, None, None, 1 0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, None, None, 1 576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, None, 1 0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 1 258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, None, None, 1 576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 1 258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, None, None, 1 576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, None, None, 1 576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, None, None, 1 0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 1 258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 1 258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, None, None, 1 576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, None, None, 1 576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, None, None, 1 0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 1 258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 1 258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, None, None, 1 576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, None, None, 1 576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, None, None, 1 576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, None, None, 1 576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, None, None, 1 0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, None, 1 0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, None, None, 1 0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, None, None, 1 576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, None, None, 1 0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 1 258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, None, None, 1 576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, None, None, 1 0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 1 258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, None, None, 1 576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, None, None, 1 576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, None, None, 1 0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, None, None, 1 0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 3 552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 1 331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, None, None, 3 960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, None, None, 1 576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, None, None, 3 0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, None, None, 1 0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, None, None, 4 1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, None, None, 4 0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, None, None, 3 1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, None, None, 3 1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, None, None, 3 1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, None, None, 3 0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, None, None, 3 0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, None, None, 3 442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, None, None, 3 442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, None, None, 3 442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, None, None, 3 442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, None, None, 3 1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, None, None, 3 1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, None, None, 3 1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, None, None, 3 1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, None, None, 1 245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, None, None, 3 960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, None, None, 3 0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, None, None, 3 0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, None, None, 3 0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, None, None, 3 0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, None, None, 1 576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, None, None, 3 0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, None, None, 7 0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, None, None, 1 0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, None, None, 4 1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, None, None, 4 0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, None, None, 3 1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, None, None, 3 1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, None, None, 3 1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, None, None, 3 0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, None, None, 3 0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, None, None, 3 442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, None, None, 3 442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, None, None, 3 442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, None, None, 3 442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, None, None, 3 1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, None, None, 3 1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, None, None, 3 1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, None, None, 3 1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, None, None, 1 393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, None, None, 3 960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, None, None, 3 0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, None, None, 3 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, None, None, 3 0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, None, None, 3 0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, None, None, 1 576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, None, None, 3 0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, None, None, 7 0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, None, None, 1 0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          524800      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            2052        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 24,427,812\n",
      "Trainable params: 24,393,380\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1606f81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-28T11:09:49.608339Z",
     "start_time": "2023-03-28T11:09:49.483146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAApAUlEQVR4nO3de3xcdZ3/8ddnZnJpkt4bCr1AiiD0QqElQt2K3NTlolyUmwtS+KF9yM9dZPXnWt1V5PFbfsIui7UusoKAiFzkUUVQUVSWiz4UpEUovcBSoLXpNb2kSZrrzHx+f5yTdJomaSYzySQn7+fjMY/MuczM58xJ5p3v9zvnHHN3REREAGKFLkBERIYOhYKIiHRSKIiISCeFgoiIdFIoiIhIJ4WCiIh0UiiIZMHMqszMzSzRh3WvMbM/DEZdIvmiUJDIMrMNZtZmZpO6zP9L+MFeVaDSsgoXkcGkUJCoexf4ZMeEmZ0AlBWuHJGhTaEgUfcgcHXG9CLgh5krmNlYM/uhmdWa2UYz+xczi4XL4mZ2u5ntNLN3gPO7eey9ZrbVzDab2b+aWTyXgs1sipk9aWa7zWy9mX0mY9kpZrbCzOrNbLuZ3RHOLzWzH5nZLjOrM7OXzWxyLnXIyKRQkKh7ERhjZjPDD+srgB91Wec7wFjgaOB0ghC5Nlz2GeCjwDygGriky2N/ACSBY8J1PgJ8OseaHwVqgCnh6/0/MzsrXPZt4NvuPgZ4D/BYOH9RuA3TgYnAZ4HmHOuQEUihICNBR2vhw8A6YHPHgoyg+Iq7N7j7BuA/gE+Fq1wGLHX3Te6+G/hmxmMnA+cBN7r7PnffAXwrfL5+MbPpwELgy+7e4u6vAt9nf2unHTjGzCa5e6O7v5gxfyJwjLun3H2lu9f3tw4ZuRQKMhI8CPwdcA1duo6ASUARsDFj3kZganh/CrCpy7IOR4WP3Rp22dQB3wMOy6HWKcBud2/ooZ7rgPcCb4RdRB8N5z8IPA08amZbzOzfzKwohzpkhFIoSOS5+0aCAefzgJ92WbyT4L/sozLmHcn+1sRWgi6ZzGUdNgGtwCR3Hxfexrj77BzK3QJMMLPR3dXj7m+5+ycJguc2YLmZlbt7u7vf7O6zgL8h6PK6GpEsKRRkpLgOOMvd92XOdPcUQb/8LWY22syOAr7A/nGHx4AbzGyamY0HlmQ8divwG+A/zGyMmcXM7D1mdnoWdZWEg8SlZlZK8OH/R+Cb4by5Ye0/AjCzq8ys0t3TQF34HGkzO9PMTgi7w+oJgi6dRR0igEJBRgh3f9vdV/Sw+B+AfcA7wB+Ah4H7wmX3EHTLvAa8wsEtjauBYmAtsAdYDhyRRWmNBAPCHbezCL5CW0XQangcuMndfxeufw6wxswaCQadr3D3ZuDw8LXrCcZNnifoUhLJiukiOyIi0kEtBRER6aRQEBGRTgoFERHppFAQEZFOw/oMjZMmTfKqqqpClyEiMqysXLlyp7tXdrdsWIdCVVUVK1b09C1DERHpjplt7GmZuo9ERKSTQkFERDopFEREpNOwHlPoTnt7OzU1NbS0tBS6FDmE0tJSpk2bRlGRTuYpMlRELhRqamoYPXo0VVVVmFmhy5EeuDu7du2ipqaGGTNmFLocEQlFrvuopaWFiRMnKhCGODNj4sSJatGJDDGRCwVAgTBMaD+JDD2RDIURr2UvpNoKXYWIDEMKhTyrq6vju9/9br8ee95551FXV9fn9b/xjW9w++23HzjTHXa/A/t29asGERnZFAp51lsoJJPJXh/71FNPMW7cuDxVoutkiEj2FAp5tmTJEt5++21OOukkvvSlL/Hcc89x2mmnccEFFzBr1iwALrroIk4++WRmz57N3Xff3fnYqqoqdu7cyYYNG5g5cyaf+cxnmD17Nh/5yEdobm7u9XVfffVVFixYwNwTT+Ti677Inj17AFi2bBmzZs1i7ty5XHHFFQA8//zznHTSSZx00knMmzePhoaG3p5aREaQyH0lNdPNP1/D2i31eX3OWVPGcNPHer4u+6233srq1at59dVXAXjuued45ZVXWL16dedXL++77z4mTJhAc3Mz73vf+/jEJz7BxIkTD3iet956i0ceeYR77rmHyy67jJ/85CdcddVVPb7u1VdfzXe+8x1OP+0DfP2L13Pzrd9i6V3f59Zbb+Xdd9+lpKSks2vq9ttv584772ThwoU0NjZSWlqa25siIpGhlsIgOOWUUw74Lv6yZcs48cQTWbBgAZs2beKtt9466DEzZszgpJNOAuDkk09mw4YNPT7/3r17qaur4/TTTwecRZd+lBf++BIAc+fO5corr+RHP/oRiUTwP8DChQv5whe+wLJly6irq+ucLyIS6U+D3v6jH0zl5eWd95977jl+97vf8ac//YmysjLOOOOMbr+rX1JS0nk/Ho8fsvuoU5ehhF/+8pe88MIL/PznP+eWW27h9ddfZ8mSJZx//vk89dRTLFy4kKeffprjjz++X9smItEyYC0FM7vPzHaY2epuln3RzNzMJoXTZmbLzGy9ma0ys/kDVddAGz16dK999Hv37mX8+PGUlZXxxhtv8OKLL+b8mmPHjmX8+PH8/ve/B5wHf/JLTl94Kul0mk2bNnHmmWdy2223sXfvXhobG3n77bc54YQT+PKXv8z73vc+3njjjZxrEJFoGMiWwg+A/wR+mDnTzKYDHwH+mjH7XODY8HYqcFf4c9iZOHEiCxcuZM6cOZx77rmcf/75Byw/55xz+K//+i9mzpzJcccdx4IFC/Lyug888ACf/exnaWrax9FTJnH/Xd8mlUpx1VVXsXfvXtydG264gXHjxvG1r32NZ599llgsxuzZszn33HPzUoOIDH/mPnBfXTSzKuAX7j4nY95y4P8CTwDV7r7TzL4HPOfuj4TrvAmc4e5be3v+6upq73qRnXXr1jFz5sz8bshwkmyFHWth1HgYX1Xoag5pxO8vkQIws5XuXt3dskEdaDazC4HN7v5al0VTgU0Z0zXhvO6eY7GZrTCzFbW1tQNUaQToMAUR6YdBCwUzKwO+Cnw9l+dx97vdvdrdqysru73E6MjW2fJTKohI9gbz20fvAWYAr4UnQpsGvGJmpwCbgekZ604L50nWFAoi0n+D1lJw99fd/TB3r3L3KoIuovnuvg14Erg6/BbSAmDvocYTpCdhGAzgWJGIRNdAfiX1EeBPwHFmVmNm1/Wy+lPAO8B64B7gfw9UXZHnB90REemzAes+cvdPHmJ5VcZ9Bz43ULWMLH7ADxGRbOg0F0NARUUFAFu2bOGSSy7pdp0zzjiDrl+/7Wrp0qU07dsXTnnWp+LuSben6BaRSFIoDCFTpkxh+fLl/X780qVLaWpqCibc83wqbhEZCRQKebZkyRLuvPPOzumO/7IbGxs5++yzmT9/PieccAJPPPHEQY/dsGEDc+YEx/k1NzdzxRVXMHPmTC6++OIDzn10/fXXU11dzezZs7npppuA4CR7W7Zs4cy/PZ8zL1kMeOepuAHuuOMO5syZw5w5c1i6dGnn6/X7FN1z53LxxRfrFN0iERPpE+LxqyWw7fX8PufhJ8C5t/a4+PLLL+fGG2/kc58Lhkgee+wxnn76aUpLS3n88ccZM2YMO3fuZMGCBVxwwQU9Xqf4rrvuoqysjHXr1rFq1Srmz99/OqhbbrmFCRMmkEqlOPvss1m1ahU33HADd9xxB8/++hdMitWROaiwcuVK7r//fl566SXcnVNPPZXTTz+d8ePH9/8U3aefzte//nVuvvlmli5dqlN0i0SEWgp5Nm/ePHbs2MGWLVt47bXXGD9+PNOnT8fd+epXv8rcuXP50Ic+xObNm9m+fXuPz/PCCy90fjjPnTuXuXPndi577LHHmD9/PvPmzWPNmjWsXbs245EHDzT/4Q9/4OKLL6a8vJyKigo+/vGPhyfPy+UU3bBo0SJeeOGFzhp1im6R4S/af6W9/Ec/kC699FKWL1/Otm3buPzyywF46KGHqK2tZeXKlRQVFVFVVdXtKbMP5d133+X222/n5ZdfZvz48VxzzTUHPk+WRzT3+xTdXegU3SLRoJbCALj88st59NFHWb58OZdeeikQ/Jd92GGHUVRUxLPPPsvGjRt7fY4PfvCDPPzwwwCsXr2aVatWAVBfX095eTljx45l+/bt/OpXv+p8zOjRo2lobAwmMg5eO+200/jZz35GU1MT+/bt4/HHH+e0007LersOPEU3PPjgg5x++uk6RbdIhES7pVAgs2fPpqGhgalTp3LEEUcAcOWVV/Kxj32ME044gerq6kP+x3z99ddz7bXXMnPmTGbOnMnJJ58MwIknnsi8efM4/vjjmT59OgsXLux8zOLFiznnwkuYMmkczz7+g8758+fP55prruGUU04B4NOf/jTz5s3rtauoJ/tP0d3E0Ucfzf33369TdItEyICeOnug6dTZ3WjaDXUbIV4Mk4fGled6M+L3l0gBDJlTZ8tg0LmPRKT/FApRo1Nni0gOIhkKw7lLLG+GwXug/SQy9EQuFEpLS9m1a9cI/sAZHtvt7uzatUsHtIkMMZH79tG0adOoqalhxF6qs7UBmveAxaBuXaGr6VVpaSnTpk0rdBkikiFyoVBUVMSMGTMKXUbh/PE78Jt/gXgJfG1HoasRkWEmct1HI146eeBPEZEsKBSipiMMPDUsBptFZGhRKERNOpVxX60FEcnOQF6j+T4z22FmqzPm/buZvWFmq8zscTMbl7HsK2a23szeNLO/Hai6Ii8zCBQKIpKlgWwp/AA4p8u83wJz3H0u8D/AVwDMbBZwBTA7fMx3zSw+gLVFl0JBRHIwYKHg7i8Au7vM+427d3xSvQh0fB/xQuBRd29193eB9cApA1VbpCkURCQHhRxT+F9Ax3mfpwKbMpbVhPMOYmaLzWyFma0Yscci9OaAMYVUz+uJiHSjIKFgZv8MJIGHsn2su9/t7tXuXl1ZWZn/4oY7tRREJAeDfvCamV0DfBQ42/efi2IzMD1jtWnhPMmWQkFEcjCoLQUzOwf4J+ACd2/KWPQkcIWZlZjZDOBY4M+DWVtkKBREJAcD1lIws0eAM4BJZlYD3ETwbaMS4LdmBvCiu3/W3deY2WPAWoJupc+5uzrE+0NjCiKSgwELBXf/ZDez7+1l/VuAWwaqnhFDLQURyYGOaI4ahYKI5EChEDUKBRHJgUIhanTuIxHJgUIhag5oKWigWUSyo1CIGnUfiUgOFApRo1AQkRwoFKImnYJY+E3jVHthaxGRYUehEDXpJCRKw/saUxCR7CgUoiadhETJ/vsiIllQKETNAS0FhYKIZEehEDVqKYhIDhQKUZNOaUxBRPpNoRA1aimISA4UClGjMQURyYFCIWrUUhCRHCgUoiadgrhCQUT6R6EQNQe0FDTQLCLZUShEjcYURCQHAxYKZnafme0ws9UZ8yaY2W/N7K3w5/hwvpnZMjNbb2arzGz+QNUVeRpTEJEcDGRL4QfAOV3mLQGecfdjgWfCaYBzgWPD22LgrgGsK9oOOE5BoSAi2RmwUHD3F4DdXWZfCDwQ3n8AuChj/g898CIwzsyOGKjaIi2dhCIdvCYi/TPYYwqT3X1reH8bMDm8PxXYlLFeTTjvIGa22MxWmNmK2tragat0uEonIV4MmFoKIpK1gg00u7sD3o/H3e3u1e5eXVlZOQCVDWPuQRDEEsFNoSAiWRrsUNje0S0U/twRzt8MTM9Yb1o4T7Lh6eBnZyjoIjsikp3BDoUngUXh/UXAExnzrw6/hbQA2JvRzSR91dEyiMXDUNCYgohkJzFQT2xmjwBnAJPMrAa4CbgVeMzMrgM2ApeFqz8FnAesB5qAaweqrkjrDIVEEAzqPhKRLA1YKLj7J3tYdHY36zrwuYGqZcQ4IBQ0piAi2dMRzVHS0V2kUBCRflIoRInGFEQkRwqFKNGYgojkSKEQJRpTEJEcKRSiRKEgIjlSKETJQQPNGlMQkewoFKLkgIFmjSmISPYUClGi7iMRyZFCIUoyQyFepFAQkawpFKJEYwoikiOFQpRoTEFEcqRQiBKNKYhIjhQKUdI1FFK6noKIZEehECUHtRQ0piAi2VEoREnnQLPGFESkfxQKUaIxBRHJkUIhShQKIpIjhUKUaExBRHJUkFAws380szVmttrMHjGzUjObYWYvmdl6M/uxmRUXorZh7YCD1zSmICLZG/RQMLOpwA1AtbvPAeLAFcBtwLfc/RhgD3DdYNc27B105TWFgohkp1DdRwlglJklgDJgK3AWsDxc/gBwUWFKG8Y0piAiORr0UHD3zcDtwF8JwmAvsBKoc/eOT7EaYGp3jzezxWa2wsxW1NbWDkbJw4fGFEQkR30KBTMrN7NYeP+9ZnaBmRX15wXNbDxwITADmAKUA+f09fHufre7V7t7dWVlZX9KiK6DToinloKIZKevLYUXgNJwPOA3wKeAH/TzNT8EvOvute7eDvwUWAiMC7uTAKYBm/v5/COXDl4TkRz1NRTM3ZuAjwPfdfdLgdn9fM2/AgvMrMzMDDgbWAs8C1wSrrMIeKKfzz9yHdB9pOspiEj2+hwKZvZ+4Ergl+G8eH9e0N1fIhhQfgV4PazhbuDLwBfMbD0wEbi3P88/onUdU/AUuBe2JhEZVhKHXgWAG4GvAI+7+xozO5rgP/t+cfebgJu6zH4HOKW/zykcHAoQdCnF+7qbRWSk69Onhbs/DzwPEA4473T3GwayMOmHjjEFC8cUIAgKhYKI9FFfv330sJmNMbNyYDWw1sy+NLClSdbSSbAYxGIZLQWNK4hI3/V1TGGWu9cTHFD2K4Kvk35qoIqSfkon94dBZyjoQjsi0nd9DYWi8LiEi4Anw6+SagRzqOk2FHQAm4j0XV9D4XvABoIDzV4ws6OA+oEqSvopncoIhYwxBRGRPurrQPMyYFnGrI1mdubAlCT9lk7uDwONKYhIP/R1oHmsmd3Rcc4hM/sPglaDDCXddh8pFESk7/rafXQf0ABcFt7qgfsHqijpJ40piEiO+voF9ve4+ycypm82s1cHoB7JhcYURCRHfW0pNJvZBzomzGwh0DwwJUm/aUxBRHLU15bCZ4EfmtnYcHoPwUnrZCjRmIKI5Kiv3z56DTjRzMaE0/VmdiOwagBrk2wpFEQkR1ldec3d68MjmwG+MAD1SC4yQyGugWYRyV4ul+O0vFUh+ZFOaUxBRHKSSyjoNBdDjbqPRCRHvY4pmFkD3X/4GzBqQCqS/lMoiEiOeg0Fdx89WIVIHujgNRHJUS7dRzLUHDCmoIPXRCR7BQkFMxtnZsvN7A0zW2dm7zezCWb2WzN7K/w5vhC1DWvqPhKRHBWqpfBt4NfufjxwIrAOWAI84+7HAs+E05KN7kIhpYvsiEjfDXoohEdFfxC4F8Dd29y9DrgQeCBc7QGCC/pINjSmICI5KkRLYQZQC9xvZn8xs++H136e7O5bw3W2AZO7e7CZLe44hXdtbe0glTxMaExBRHJUiFBIAPOBu9x9HrCPLl1F7u70cByEu9/t7tXuXl1ZWTngxQ4r6SSYDl4Tkf4rRCjUADXu/lI4vZwgJLab2REA4c8dBahteNNAs4jkaNBDwd23AZvM7Lhw1tnAWuBJ9p95dRHwxGDXNuwpFEQkR309dXa+/QPwkJkVA+8A1xIE1GNmdh2wkeAKb5KNAy6yo4FmEcleQULB3V8FqrtZdPYglxItB1xkRwPNIpI9HdEcJeo+EpEcKRSi5IBQKNo/T0SkjxQKUaIxBRHJkUIhSg4YU4gBppaCiGRFoRAlmd1HENxXKIhIFhQKUaJQEJEcKRSiIp0GvJtQ0JiCiPSdQiEqOloEHWMKHffVUhCRLCgUoqIzFLq2FHQ9BRHpO4VCVPQYCmopiEjfKRSiosdQ0JiCiPSdQiEqOj78NaYgIjlQKESFuo9EJA8UClGhUBCRPFAoRIXGFEQkDxQKUdE5ppAZChpTEJHsKBSiotuD19R9JCLZUShERXfdR/EihYKIZKVgoWBmcTP7i5n9IpyeYWYvmdl6M/txeP1m6SuNKYhIHhSypfB5YF3G9G3At9z9GGAPcF1BqhquNKYgInlQkFAws2nA+cD3w2kDzgKWh6s8AFxUiNqGLY0piEgeFKqlsBT4JyAdTk8E6ty94xOsBpja3QPNbLGZrTCzFbW1tQNe6LCh4xREJA8GPRTM7KPADndf2Z/Hu/vd7l7t7tWVlZV5rm4YUyiISB4kDr1K3i0ELjCz84BSYAzwbWCcmSXC1sI0YHMBahu+ug2FuAaaRSQrg95ScPevuPs0d68CrgD+292vBJ4FLglXWwQ8Mdi1DWvdDjSrpSAi2RlKxyl8GfiCma0nGGO4t8D1DC89DTSndJEdEem7QnQfdXL354DnwvvvAKcUsp5hTccpiEgeDKWWguSixzEFdR+JSN8pFKJCYwoikgcKhajQwWsikgcKhajQmIKI5IFCISp08JqI5IFCISoUCiKSBwqFqOgcaNaYgoj0n0IhKnpqKXgK3AtTk4gMOwqFqOgpFECDzSLSZwqFqOjp4LXMZSIih6BQiIqeDl4DhYKI9JlCISrSScAglrFLFQoikiWFQlSkkwe2EkBjCiKSNYVCVHQbChpTEJHsKBSiIp3qpaWgUBCRvlEoREU6eeCBa5ARCrrQjoj0jUIhKjSmICJ5oFCICo0piEgeDHoomNl0M3vWzNaa2Roz+3w4f4KZ/dbM3gp/jh/s2oY1jSmISB4UoqWQBL7o7rOABcDnzGwWsAR4xt2PBZ4Jp6Wveh1TUCiISN8Meii4+1Z3fyW83wCsA6YCFwIPhKs9AFw02LUNa72OKSgURKRvCjqmYGZVwDzgJWCyu28NF20DJvfwmMVmtsLMVtTW1g5OocNBd6EQ10CziGSnYKFgZhXAT4Ab3b0+c5m7O9Dt+Z7d/W53r3b36srKykGodJhQS0FE8qAgoWBmRQSB8JC7/zScvd3MjgiXHwHsKERtw1Y6pTEFEclZIb59ZMC9wDp3vyNj0ZPAovD+IuCJwa5tWHN9+0hEcpc49Cp5txD4FPC6mb0azvsqcCvwmJldB2wELitAbcOXDl4TkTwY9FBw9z8A1sPiswezlkjRwWsikgc6ojkqNKYgInmgUIgKHbwmInmgUIgKjSmISB4oFKJCYwoikgcKhajo7YR4KV1PQUT6RqEQFRpTEJE8UChEhU5zISJ5oFCICg00i0geKBSiotsxBQ00i0h2FApR0e2YQtH+ZSIifaBQiAqNKYhIHigUokJjCiKSBwqFqOh2TCEGmFoKItJnCoWo6G5MAYKgUCiISB8pFKKiu+4jUCiISFYUClHRayhoTEFE+kahkCnZCm/+CtqbC11JdtJp8HQPoRCH5DDbHhEpGIUCgDus+wXceSo8cgXcfx40bCt0VX3nYUuguzGFKSfBqw/Dpj8PakkiMjwNuVAws3PM7E0zW29mSwbiNTa+9AS7vjmHbXd8gK13XUD9nWfCj6+kzYppPO1reO2bcM9ZsPW1gx/sDi31Q6tLpmPMoLuWwse/D2OmwMOXwc63BrcuERl2Bv0azb0xszhwJ/BhoAZ42cyedPe1+XydrS1F7G6ZzuimesbXbaSBdv49dQ0Pbzmb1JY4s2P/zL3tdzDuex9mc9GRmBlxnApvYExyN0XeRltsFDsr3svuMTNpLplEmgSpWBxPlBEvG0+8fDylsTSlzdspad5OghQ+Zgo2dhrx0jFYaz2x1r3E0u142USsYiIJMxJbVpLY/BKxPe+QGnsUyQnH0j62ijgpilLNxL2dWPkkYmOOwEYfHgRBe1OwYd2FQkUl6b/7CXbfh/EHP077eUtJJPcRa96F4VA6NryNg5Ixwf2i0qA7yj147sbt0Lgj6FYbdxRMmAGjxofL90HTbqh9A7avgbq/woSj4fATYPIcKC4HiwW3eBFYeHnuVHvwnPt2BN1fiWKIl0CqDdoag1t7C6Tbg3Xdg5aQxQAPuvqSLRAvDl5v4jFQXhnU2Nqw/z0xg2Qb1NcEte2rhbFHButPmAFFo4L3LZbYX1s6DXs3Qe2bsOut4H2ZeExwK5uQcfqQFDTvgaZdB95iiaCmCUdD+WH7tyHVFtySrUHrLh5us8WgtT64tTcHr1c2AUZNCN6XDu7QUgf7dgXvZcnooP49G2Db67BjLZRNhGmnwBEnBvsxlYSWvZBqDd87C+pLFIevX7x/u7tKp4P3sW1fsJ/bmoJt6fg9SZQG7+mu9cH7VVwBFYcF+6G4IqgtXgy734atq4Lfj9a9wXZ4GsYdCdNPgemnwugp+9+n2jfgnWfhneeD6WM/BO89B8ZOg5qVUPMyNG4L9/uxMHZq8I9RsjX42bFd6RTsWBO89p53ofL44LWmvS9478zo/Mp2x+Pr/go7/yfYptIxcNis4Db68GB7M39Hki3B72KiNPidqNsEbz4Fb/wC9mwM6pt0bFBj5XHBrWLy/r+bZBuUVECipJ+fZAPD3L3QNXQys/cD33D3vw2nvwLg7t/sbv3q6mpfsWJFv1+vsTXJjvoWahtaaWxN0tiapL65ndqGVvbt2sJZNXcyKllHKu2kHfZ4BbU+htrUaCaldzLL3mWWbaTMWg/5Wik34ta39/qv6Ure8mlMtx3MsG0UWd9aJf+c/DQ/Tp+NWfB7l3bHCe7Ptbd5tPhf+1RrX7SRoJiDv9VUTzlj2Nfr49pJUE5LXurIlMaIkdvvc5rgj76350kRo50ExbTn/HqHkiROMyW0WzEV3tjte565boLgdyV4n4so59DjSWmMNDFSxPDwvuGMIj+/Kx122zj2Moa0BR0UU9Jbe32N/4kdTZoYx6fXHzA/RYx9lDOGhj69biNlbI1N5sj0Zkpo69Njevr9bqUYwynmwGuUZL7379p03o0fxZT0NqanNx+wD9pJUNTledtI0MQoDIiTIk6qcz+AESdFgiRFJEkSo50ikiR4c8anqF50W5+2pyszW+nu1d0tG1ItBWAqsCljugY4NXMFM1sMLAY48sgjc3qxipIEFZUVHF1Z0c3S44Aze318MpWmpT1JfbINS7dj6RTtLY001++ipX4XbWmjZdRkWksraU2BN2wj1rAFWhtpLx5De2IMSYuTaNlDonUXJNvZOXY2zSWVAGyJGStJUd66gzYS7PMSmtNxSlp3U9qyg1EttcRI48RIxRJMGlPN4lgpDsQMDMMM4jGjKH4cP2s9kTHNm2iIjaU+NpaUG8XJBoqTjZQmGyhJNVKSbCCebiXlMdIY7VZMQ2ICDYnxJK2Iie3bmdi2mYr23bRaCS2xUpqsnNqSKraPmkFrYjTlyT0c3vw2k1vfJZFuw3DM0yS8nbi3k/B2WuIV1CcmUh8fR9oSxNPBsrTFaY2V0R4vIxkrIRUrIm0JHCPmaYwU7tBqxbRRTCLdwmFtm6lsq6EitYfWWBktsTLarISYQcyMtCWoKzqMPcWH0xAbx9i2rUxs3cSE1s0kvJ2Yp4h7kpgFwR0zZ2/xZLaXVFFbMp3iVDMTmjcysXUTo9L7SITb0B4rpTE+lsb4GJoS42hKjKO5aByJdDsTWjYxoa2GsuRekiRIWoKkFXXeUsQo9naKaCdGmtZ4BW2JCpKxEkal91Ge3MuoVD2JVDNFqWZi6Taa4qNpiE+gIT6WOClK000Up5qoK5rMllHHsLPkKMrTezmqaS1HNa+lyNtoio2mKV5B0orBPdwXKeLeTjzdFn7gpImTJk4qWE6atBttsVG0xEbRaqW0xUpps1JSlqA0tY9R6UaK0i3sKZ7MruIj2VN8OMXezOjkbira6yj2ZopSLSTSbewuPpya0mNoSEwMGgkE/7DEPMnU1rc5unkNFemGYD/HEuwumsz6svk0xMeSdhid3MWsfX9mdHI3G0qPZ0Pp8bRaGeXeyOHtmxiX3El75/saDz5A08GH9taSo9iVOIK0xUh4O9Nb3+LIljdJpNsgDPQ0cdoteCcaiiezp6yKlrIjSKRbmLDvHSY2vU1Zso6idBvxdAtgtFkJ7bESHCihnWJvY19iLGvK/4btxdNIOwTtEGdscheT2zZyWOtGxrbX0h4robXjvfQWRqX3UZpuCoLZ4qTCUDYP9oVbgpQlSFsCIx3+rSQZddicnD7/ejLUWgqXAOe4+6fD6U8Bp7r733e3fq4tBRGRkai3lsJQG2jeDEzPmJ4WzhMRkUEw1ELhZeBYM5thZsXAFcCTBa5JRGTEGFJjCu6eNLO/B54G4sB97r6mwGWJiIwYQyoUANz9KeCpQtchIjISDbXuIxERKSCFgoiIdFIoiIhIJ4WCiIh0GlIHr2XLzGqBjf18+CRgZx7LGS5G4naPxG2GkbndI3GbIfvtPsrdK7tbMKxDIRdmtqKnI/qibCRu90jcZhiZ2z0Stxnyu93qPhIRkU4KBRER6TSSQ+HuQhdQICNxu0fiNsPI3O6RuM2Qx+0esWMKIiJysJHcUhARkS4UCiIi0mlEhoKZnWNmb5rZejNbUuh6BoKZTTezZ81srZmtMbPPh/MnmNlvzeyt8Of4Qtc6EMwsbmZ/MbNfhNMzzOylcJ//ODw1e2SY2TgzW25mb5jZOjN7/0jY12b2j+Hv92oze8TMSqO4r83sPjPbYWarM+Z1u38tsCzc/lVmNj+b1xpxoWBmceBO4FxgFvBJM5tV2KoGRBL4orvPAhYAnwu3cwnwjLsfCzwTTkfR54F1GdO3Ad9y92OAPcB1Balq4Hwb+LW7Hw+cSLDtkd7XZjYVuAGodvc5BKfbv4Jo7usfAOd0mdfT/j0XODa8LQbuyuaFRlwoAKcA6939HXdvAx4FLixwTXnn7lvd/ZXwfgPBh8RUgm19IFztAeCighQ4gMxsGnA+8P1w2oCzgOXhKpHabjMbC3wQuBfA3dvcvY4RsK8JTv8/yswSQBmwlQjua3d/AdjdZXZP+/dC4IceeBEYZ2ZH9PW1RmIoTAU2ZUzXhPMiy8yqgHnAS8Bkd98aLtoGTC5UXQNoKfBPQDqcngjUuXsynI7aPp8B1AL3h11m3zezciK+r919M3A78FeCMNgLrCTa+zpTT/s3p8+4kRgKI4qZVQA/AW509/rMZR58HzlS30k2s48CO9x9ZaFrGUQJYD5wl7vPA/bRpasoovt6PMF/xTOAKUA5B3exjAj53L8jMRQ2A9MzpqeF8yLHzIoIAuEhd/9pOHt7R1My/LmjUPUNkIXABWa2gaBr8CyC/vZxYRcDRG+f1wA17v5SOL2cICSivq8/BLzr7rXu3g78lGD/R3lfZ+pp/+b0GTcSQ+Fl4NjwGwrFBANTTxa4prwL+9HvBda5+x0Zi54EFoX3FwFPDHZtA8ndv+Lu09y9imDf/re7Xwk8C1wSrhap7Xb3bcAmMzsunHU2sJaI72uCbqMFZlYW/r53bHdk93UXPe3fJ4Grw28hLQD2ZnQzHdKIPKLZzM4j6HeOA/e5+y2FrSj/zOwDwO+B19nft/5VgnGFx4AjCU47fpm7dx3AigQzOwP4P+7+UTM7mqDlMAH4C3CVu7cWsLy8MrOTCAbWi4F3gGsJ/umL9L42s5uBywm+bfcX4NME/eeR2tdm9ghwBsEpsrcDNwE/o5v9GwbkfxJ0pTUB17r7ij6/1kgMBRER6d5I7D4SEZEeKBRERKSTQkFERDopFEREpJNCQUREOikURHphZikzezXjlreTyplZVeZZL0WGgsShVxEZ0Zrd/aRCFyEyWNRSEOkHM9tgZv9mZq+b2Z/N7JhwfpWZ/Xd4HvtnzOzIcP5kM3vczF4Lb38TPlXczO4JrwnwGzMbVbCNEkGhIHIoo7p0H12esWyvu59AcPTo0nDed4AH3H0u8BCwLJy/DHje3U8kOC/RmnD+scCd7j4bqAM+MaBbI3IIOqJZpBdm1ujuFd3M3wCc5e7vhCce3ObuE81sJ3CEu7eH87e6+yQzqwWmZZ5uITyl+W/Di6RgZl8Gitz9Xwdh00S6pZaCSP95D/ezkXlOnhQa55MCUyiI9N/lGT//FN7/I8HZWQGuJDgpIQSXS7weOq8fPXawihTJhv4rEendKDN7NWP61+7e8bXU8Wa2iuC//U+G8/6B4ApoXyK4Gtq14fzPA3eb2XUELYLrCa4WJjKkaExBpB/CMYVqd99Z6FpE8kndRyIi0kktBRER6aSWgoiIdFIoiIhIJ4WCiIh0UiiIiEgnhYKIiHT6/3AwcvEuP28aAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the model accuracy and validation accuracy\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['train loss','validation loss'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edwin_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
